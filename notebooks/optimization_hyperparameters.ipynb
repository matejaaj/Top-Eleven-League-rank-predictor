{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessing import *\n",
    "from src.models import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df = load_data('../data/jobfair_train.csv')\n",
    "\n",
    "columns_to_normalize = [\n",
    "    'days_active_last_28_days', 'session_count_last_28_days',\n",
    "    'avg_stars_top_11_players', 'tokens_spent_last_28_days',]\n",
    "\n",
    "columns_to_drop = [\n",
    "    'morale_boosters_stash', 'rests_stash', 'tokens_stash', 'tokens_spent_last_28_days',\n",
    "    'avg_training_factor_top_11_players', 'avg_age_top_11_players',\n",
    "    'league_match_watched_count_last_28_days', 'global_competition_level',\n",
    "    'avg_stars_top_14_players', 'days_active_last_28_days', 'session_count_last_28_days',\n",
    "    'playtime_last_28_days', 'league_match_won_count_last_28_days', 'training_count_last_28_days',\n",
    "    'avg_stars_top_11_players', 'global_competition_level', 'club_id','cohort_season','season','dynamic_payment_segment', 'registration_country', 'registration_platform_specific'\n",
    "]\n",
    "\n",
    "df = preprocess_data(df, columns_to_normalize, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Najbolji parametri: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = league_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "print(f\"Best params: {best_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Najbolji parametri: {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (50, 50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(scale(X_train), y_train)\n",
    "\n",
    "best_parameters = grid_search.best_params_\n",
    "print(f\"Best params: {best_parameters}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
